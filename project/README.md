# Model Monitoring & Drift Detection in Phishing Detection

This project implements a comprehensive production-ready system for monitoring a deployed phishing detection model. It detects Data Drift, Prediction Drift, Concept Drift, and Embedding Drift, and supports automated retraining.

## ðŸ“‚ Project Structure

```
project/
â”‚â”€â”€ data/                   # Data storage (Feature Store, Logs)
â”‚â”€â”€ models/                 # Trained models and metrics
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/          # API, Kafka Producer/Consumer, Schema
â”‚   â”œâ”€â”€ monitoring/         # Monitoring logic
â”‚   â”œâ”€â”€ drift_detectors/    # Drift detection algorithms (PSI, KS, River, etc.)
â”‚   â”œâ”€â”€ dashboards/         # Dashboard scripts (Evidently)
â”‚   â”œâ”€â”€ retraining/         # Automated retraining pipeline
â”‚   â”œâ”€â”€ utils/              # Utilities (Alert Manager)
â”‚â”€â”€ scripts/                # Batch monitoring scripts
â”‚â”€â”€ dags/                   # Airflow DAGs
â”‚â”€â”€ infra/                  # Infrastructure config (Grafana)
â”‚â”€â”€ docker/                 # Docker configuration
â”‚â”€â”€ tests/                  # Unit tests
â”‚â”€â”€ requirements.txt        # Python dependencies
â”‚â”€â”€ README.md               # This file
```

## ðŸš€ Getting Started

### Prerequisites
- Python 3.8+
- Docker & Docker Compose

### Installation

1.  **Clone the repository**
2.  **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

### Running Locally (Docker)

To start Kafka, Zookeeper, and the API:

```bash
cd docker
docker-compose up --build
```

The API will be available at `http://localhost:8000`.

### ðŸ“Š Monitoring Modules

#### 1. Data Ingestion
- **API**: Send predictions to `POST /predict`.
- **Kafka**: Logs are pushed to `phishing_logs` topic.
- **Consumer**: Reads from Kafka and writes to Feature Store (Parquet).

#### 2. Drift Detection
- **Covariate Drift**: PSI, KS-test, Chi-square, MMD.
- **Prediction Drift**: KL Divergence, JS Divergence.
- **Concept Drift**: Real-time detection using River (ADWIN, DDM).
- **Embedding Drift**: Wasserstein distance on PCA components.

#### 3. Batch Monitoring
Run daily checks manually or via Cron:

```bash
# Run all checks
./scripts/cron_jobs.sh
```

Individual scripts:
- `scripts/batch_psi_check.py`
- `scripts/batch_ks_check.py`
- `scripts/batch_prediction_drift.py`
- `scripts/batch_generate_report.py`

#### 4. Real-time Monitoring
Start the real-time monitor:

```bash
python scripts/realtime_monitor.py
```

#### 5. Dashboards
- **Evidently**: Generate HTML report:
    ```bash
    python src/dashboards/evidently_dashboard.py
    ```
    Open `data/dashboards/evidently_report_YYYY-MM-DD.html`.
- **Grafana**: Import `infra/grafana/dashboards/dashboard.json` into your Grafana instance.

### ðŸš¨ Alerts
Alerts are sent via Slack (webhook) or logged locally to `data/alerts/incident_log.json`. Configure `SLACK_WEBHOOK_URL` env var.

### ðŸ”„ Automated Retraining
Triggered automatically if drift is detected (via Airflow/Cron) or manually:

```bash
python src/retraining/train.py
```

## ðŸ›  Deployment

- **Airflow**: Copy `dags/drift_check_dag.py` to your Airflow DAGs folder.
- **Cron**: Schedule `scripts/cron_jobs.sh` in crontab.

## ðŸ“ Architecture

1.  **Model Service** -> **API** -> **Kafka**
2.  **Kafka** -> **Consumer** -> **Feature Store (Parquet)**
3.  **Kafka** -> **Real-time Monitor** -> **Alerts**
4.  **Batch Scripts** -> Read **Feature Store** -> **Drift Detection** -> **Reports**
5.  **Orchestrator** -> Triggers **Retraining** if Drift Detected.
